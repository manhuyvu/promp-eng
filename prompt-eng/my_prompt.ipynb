{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Prompt Engineering Lab\n",
    "\n",
    "This assignment will focus on prompting an LLM to create a requirement analysis for developing a role playing game. Using (1) provide examples of zero shot prompting and (2)prompts to create prompts and sequences of prompts.\n",
    "## References:\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Zero Shot Prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _pipeline import create_payload, model_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "**Requirement Analysis for MMO Video Game Solution**\n",
      "\n",
      "**Game Setting**\n",
      "----------------\n",
      "\n",
      "The game is set in a fantasy world with various kingdoms, factions, and magical realms. The world is divided into different regions, each with its own unique culture, architecture, and challenges.\n",
      "\n",
      "**Core Features**\n",
      "-----------------\n",
      "\n",
      "1. **Character Creation**: Players create their characters by selecting from various races, classes, and backgrounds.\n",
      "2. **Storyline**: The game features a dynamic storyline that changes based on the player's actions\n",
      "Time taken: 10.306s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PROMPT TEMPLATE PROMPTING\n",
    "##\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "PROMPT = MESSAGE\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using automated Self Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'ask 1 question to help clarify prompt:consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: To better understand your requirements for the MMO video game solution, can you please confirm that we're aiming for a fantasy-themed game with a vast open-world environment? If so, what specific aspects of the world setting would you like to focus on (e.g., magical systems, geography, culture)?\n",
      "Time taken: 4.764s\n",
      "{'model': 'llama3.2:latest', 'prompt': \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.in relation to these questionsTo better understand your requirements for the MMO video game solution, can you please confirm that we're aiming for a fantasy-themed game with a vast open-world environment? If so, what specific aspects of the world setting would you like to focus on (e.g., magical systems, geography, culture)?\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: Let's dive into the details.\n",
      "\n",
      "**Game Concept**\n",
      "\n",
      "We're targeting a fantasy-themed, open-world adventure game set in a vast, sprawling realm. The game will feature a richly detailed environment with diverse landscapes, climates, and ecosystems.\n",
      "\n",
      "**Core Mechanics**\n",
      "\n",
      "The gameplay will revolve around exploration, combat, crafting, and character development. Players will be able to:\n",
      "\n",
      "1. **Explore**: Venture into uncharted territories, discover hidden locations, and uncover secrets.\n",
      "2. **Combat**: Engage\n",
      "Time taken: 7.795s\n"
     ]
    }
   ],
   "source": [
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.\"\n",
    "\n",
    "#### (2) Prompt LLM to ask question in regards to message\n",
    "S_ASK = \"ask 1 question to help clarify prompt:\"\n",
    "PROMPT = S_ASK + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "#use original prompt and question to formulate final reponse\n",
    "new_prompt = \"in relation to these questions\"\n",
    "PROMPT = MESSAGE + new_prompt + response \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying/Optimizing Parameters for Self Ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll modify temperature for .2, .5. and .9. This parameter controls randomnesss or creativity in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'ask 1 question to help clarify prompt:consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: To provide a more accurate requirement analysis, can you please tell me what type of MMO (Massively Multiplayer Online) experience you envision? For example:\n",
      "\n",
      "* Is it a high-fantasy RPG with a large open world to explore?\n",
      "* Is it a sci-fi MMORPG set in space or on a futuristic planet?\n",
      "* Does it have a focus on action-packed combat, exploration, and puzzle-solving?\n",
      "* Or is it more focused on building relationships, crafting, and social interactions?\n",
      "\n",
      "Please let\n",
      "Time taken: 8.232s\n",
      "{'model': 'llama3.2:latest', 'prompt': 'consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.in relation to these questionsTo provide a more accurate requirement analysis, can you please tell me what type of MMO (Massively Multiplayer Online) experience you envision? For example:\\n\\n* Is it a high-fantasy RPG with a large open world to explore?\\n* Is it a sci-fi MMORPG set in space or on a futuristic planet?\\n* Does it have a focus on action-packed combat, exploration, and puzzle-solving?\\n* Or is it more focused on building relationships, crafting, and social interactions?\\n\\nPlease let', 'stream': False, 'options': {'temperature': 0.2, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: I'd love to help you explore the possibilities of our game. Here are some ideas to get us started:\n",
      "\n",
      "**Setting:**\n",
      "\n",
      "* **Fantasy Realm:** Explore a mystical world filled with ancient magic, mythical creatures, and legendary artifacts.\n",
      "* **Cyberpunk Metropolis:** Delve into a futuristic city where technology and humanity coexist in a world of high-stakes intrigue and danger.\n",
      "* **Post-Apocalyptic Wasteland:** Survive in a harsh environment where resources are scarce and\n",
      "Time taken: 7.915s\n"
     ]
    }
   ],
   "source": [
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.\"\n",
    "\n",
    "#### (2) Prompt LLM to ask question in regards to message\n",
    "S_ASK = \"ask 1 question to help clarify prompt:\"\n",
    "PROMPT = S_ASK + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "#use original prompt and question to formulate final reponse\n",
    "new_prompt = \"in relation to these questions\"\n",
    "PROMPT = MESSAGE + new_prompt + response \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=.2, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seccond, we'll modify temperature for num_ctx for 10, 50, and 100. This controls how much of the previous response is used as context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'ask 1 question to help clarify prompt:consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: To better understand the requirements for your MMO solution, I have one clarifying question:\n",
      "\n",
      "Will your MMO be set in a high-fantasy world, or will it take place in a more modern-day or science fiction environment? This could help inform decisions about character stats, skills, and equipment, as well as the overall tone and setting of the game.\n",
      "Time taken: 5.644s\n",
      "{'model': 'llama3.2:latest', 'prompt': 'consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.in relation to these questionsTo better understand the requirements for your MMO solution, I have one clarifying question:\\n\\nWill your MMO be set in a high-fantasy world, or will it take place in a more modern-day or science fiction environment? This could help inform decisions about character stats, skills, and equipment, as well as the overall tone and setting of the game.', 'stream': False, 'options': {'temperature': 1, 'num_ctx': 10, 'num_predict': 100}}\n",
      "self ask question: The answer is \"none\" or more specifically, the concept of \"duality\" can be seen in various aspects of human life. The present focus on natural fiber textiles and nonwoven fabrics\n",
      "**Dyeing and Finishing**\n",
      "\n",
      "The final step in a project's development is not just about the technology itself but how itâ€™s used to deliver care and support for individuals with learning disabilities, behavioral challenges, or other issues that may be impacting your mental well-being and performance.\n",
      "\n",
      "### Features\n",
      "\n",
      "*\n",
      "Time taken: 8.538s\n"
     ]
    }
   ],
   "source": [
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.\"\n",
    "\n",
    "#### (2) Prompt LLM to ask question in regards to message\n",
    "S_ASK = \"ask 1 question to help clarify prompt:\"\n",
    "PROMPT = S_ASK + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "#use original prompt and question to formulate final reponse\n",
    "new_prompt = \"in relation to these questions\"\n",
    "PROMPT = MESSAGE + new_prompt + response \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1, \n",
    "                         num_ctx=10, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll modify num_predict 10, 50, and 200. This controls how many tokens can be used in the final response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'ask 1 question to help clarify prompt:consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "self ask question: Here's a question to clarify the requirements:\n",
      "\n",
      "Can you please confirm whether the MMO game has a specific \"lore\" or storyline in mind, or if it will be more of an open-world sandbox experience with player-driven narratives? This could impact how we approach world setting, character creation, and overall design.\n",
      "Time taken: 4.929s\n",
      "{'model': 'llama3.2:latest', 'prompt': 'consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.in relation to these questionsHere\\'s a question to clarify the requirements:\\n\\nCan you please confirm whether the MMO game has a specific \"lore\" or storyline in mind, or if it will be more of an open-world sandbox experience with player-driven narratives? This could impact how we approach world setting, character creation, and overall design.', 'stream': False, 'options': {'temperature': 1, 'num_ctx': 100, 'num_predict': 200}}\n",
      "self ask question: Let's dive into some possible directions for our system.\n",
      "\n",
      "**Open-World Sandbox Experience:**\n",
      "\n",
      "*   World setting: A vast, uncharted territory with diverse biomes, climates, and cultures.\n",
      "*   Character creation: Players can choose their appearance, skills, and starting equipment.\n",
      "*   Gameplay mechanics: Focus on exploration, survival, and player choice. The open world allows players to discover new locations, form alliances, and pursue various goals.\n",
      "\n",
      "**Immersive Storytelling**\n",
      "\n",
      "In an immersive world, the narrative is deeply intertwined with the environment and gameplay mechanics. This approach creates a unique experience for players as they navigate the game's story through character interactions, journal entries, and environmental clues.\n",
      "\n",
      "To incorporate this concept into your project:\n",
      "\n",
      "1.  **Develop a rich backstory**: Create a detailed history of the game's world, including its culture, politics, and mythology.\n",
      "2.  **Design engaging characters**: Craft well-rounded characters with complex motivations and relationships to drive the story forward.\n",
      "\n",
      "Time taken: 14.91s\n"
     ]
    }
   ],
   "source": [
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"consider you are developing a solution for an mmo video game. Provide the requirement Analysis for this solution considering classes, world setting, character stats, skills, and equipment.\"\n",
    "\n",
    "#### (2) Prompt LLM to ask question in regards to message\n",
    "S_ASK = \"ask 1 question to help clarify prompt:\"\n",
    "PROMPT = S_ASK + MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')\n",
    "\n",
    "#use original prompt and question to formulate final reponse\n",
    "new_prompt = \"in relation to these questions\"\n",
    "PROMPT = MESSAGE + new_prompt + response \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=200)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "# prints the question that was asked\n",
    "time, response = model_req(payload=payload)\n",
    "print(\"self ask question:\", response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
